{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas groupby 集計 高速化\n",
    "\n",
    "[Pandas groupby 集計を10倍高速化する3つの基本テクニック](https://www.salesanalytics.co.jp/datascience/datascience268/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  region channel  sales\n",
      "0     関東      店舗    100\n",
      "1     関東   オンライン    200\n",
      "2     関西      店舗    150\n",
      "3     関西   オンライン     80\n",
      "4     関西      店舗    120\n",
      "5     中部   オンライン     90\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# まずは6行だけの小さなデータで試してみます\n",
    "df_sample = pd.DataFrame({\n",
    "    'region':  ['関東', '関東', '関西', '関西', '関西', '中部'],\n",
    "    'channel': ['店舗', 'オンライン', '店舗', 'オンライン', '店舗', 'オンライン'],\n",
    "    'sales':   [100, 200, 150, 80, 120, 90]\n",
    "})\n",
    "# データの中身を確認\n",
    "print(df_sample)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region\n",
      "中部     90\n",
      "関東    300\n",
      "関西    350\n",
      "Name: sales, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 地域ごとの売上合計を計算\n",
    "result = df_sample.groupby('region')['sales'].sum()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 複数の条件でグループ化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  region channel  sales\n",
      "0     中部   オンライン   90.0\n",
      "1     関東   オンライン  200.0\n",
      "2     関東      店舗  100.0\n",
      "3     関西   オンライン   80.0\n",
      "4     関西      店舗  135.0\n"
     ]
    }
   ],
   "source": [
    "# 地域×チャネル別の平均売上を計算\n",
    "# as_index=Falseを付けると、結果が見やすい表形式になります\n",
    "result = df_sample.groupby(['region', 'channel'], as_index=False)['sales'].mean()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 高速化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 検証用データの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データのサイズ: 1,000,000行\n",
      "  region channel       sales\n",
      "0     東北   オンライン  497092.948\n",
      "1     九州   パートナー  482762.557\n",
      "2     中部      店舗  497356.177\n",
      "3     九州      店舗  494995.646\n",
      "4     九州      電話  490321.006\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "# 乱数のシードを固定\n",
    "np.random.seed(42)\n",
    "# 100万行のデータを生成\n",
    "N = 1_000_000  # アンダースコアで区切ると読みやすい\n",
    "regions = [\"関東\", \"関西\", \"中部\", \"東北\", \"九州\"]\n",
    "channels = [\"オンライン\", \"店舗\", \"パートナー\", \"電話\"]\n",
    "df = pd.DataFrame({\n",
    "    \"region\": np.random.choice(regions, size=N),    # 地域をランダムに選択\n",
    "    \"channel\": np.random.choice(channels, size=N),   # チャネルをランダムに選択\n",
    "    \"sales\": np.random.normal(500000, 10000, size=N).round(3)  # 平均500000、標準偏差10000の正規分布\n",
    "})\n",
    "print(f\"データのサイズ: {len(df):,}行\")  # カンマ区切りで表示\n",
    "print(df.head())  # 最初の5行を確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最適化前の処理速度を測定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "現在のデータ型:\n",
      "region      object\n",
      "channel     object\n",
      "sales      float64\n",
      "dtype: object\n",
      "\n",
      "メモリ使用量: 174.52 MB\n",
      "\n",
      "処理時間（最適化前）: 0.120 秒\n"
     ]
    }
   ],
   "source": [
    "# データ型を確認（regionとchannelがobject型になっているはず）\n",
    "print(\"現在のデータ型:\")\n",
    "print(df.dtypes)\n",
    "print()\n",
    "# メモリ使用量を確認\n",
    "memory_mb = df.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f\"メモリ使用量: {memory_mb:.2f} MB\")\n",
    "print()\n",
    "# 速度を表示\n",
    "start_time = time.perf_counter()  # 正確な時間測定用のタイマーを開始\n",
    "result_before = df.groupby([\"region\", \"channel\"])['sales'].agg(['sum', 'mean', 'count'])\n",
    "time_before = time.perf_counter() - start_time\n",
    "print(f\"処理時間（最適化前）: {time_before:.3f} 秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ型を最適化して再測定\n",
    "\n",
    "* カテゴリ型\n",
    "* 実際に存在するグループだけを処理\n",
    "* 並べ替えをスキップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最適化後のデータ型:\n",
      "region     category\n",
      "channel    category\n",
      "sales       float64\n",
      "dtype: object\n",
      "\n",
      "メモリ使用量: 9.54 MB\n",
      "メモリ削減率: 94.5%\n",
      "\n",
      "処理時間（最適化後）: 0.033 秒\n",
      "高速化率: 3.6倍\n"
     ]
    }
   ],
   "source": [
    "# データをコピー（元のデータは残しておく）\n",
    "df_optimized = df.copy()\n",
    "# カテゴリ型に変換\n",
    "df_optimized[\"region\"] = df_optimized[\"region\"].astype(\"category\")\n",
    "df_optimized[\"channel\"] = df_optimized[\"channel\"].astype(\"category\")\n",
    "print(\"最適化後のデータ型:\")\n",
    "print(df_optimized.dtypes)\n",
    "print()\n",
    "# メモリ使用量を再確認\n",
    "memory_mb_optimized = df_optimized.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f\"メモリ使用量: {memory_mb_optimized:.2f} MB\")\n",
    "print(f\"メモリ削減率: {(1 - memory_mb_optimized/memory_mb)*100:.1f}%\")\n",
    "print()\n",
    "# 最適化された処理の実行\n",
    "start_time = time.perf_counter()\n",
    "result_after = df_optimized.groupby(\n",
    "    [\"region\", \"channel\"], \n",
    "    observed=True,  # 実際に存在するグループだけを処理\n",
    "    sort=False      # 並べ替えをスキップ\n",
    ")['sales'].agg(['sum', 'mean', 'count'])\n",
    "# 速度を表示\n",
    "time_after = time.perf_counter() - start_time\n",
    "print(f\"処理時間（最適化後）: {time_after:.3f} 秒\")\n",
    "print(f\"高速化率: {time_before / time_after:.1f}倍\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# デモ用にCSVファイルを作成\n",
    "df.to_csv(\"sales_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## チャンク処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ファイル 'sales_data.csv' を 20,000行ずつ処理します...\n",
      "  チャンク 1 を処理中...\n",
      "  チャンク 2 を処理中...\n",
      "  チャンク 3 を処理中...\n",
      "  チャンク 4 を処理中...\n",
      "  チャンク 5 を処理中...\n",
      "  チャンク 6 を処理中...\n",
      "  チャンク 7 を処理中...\n",
      "  チャンク 8 を処理中...\n",
      "  チャンク 9 を処理中...\n",
      "  チャンク 10 を処理中...\n",
      "  チャンク 11 を処理中...\n",
      "  チャンク 12 を処理中...\n",
      "  チャンク 13 を処理中...\n",
      "  チャンク 14 を処理中...\n",
      "  チャンク 15 を処理中...\n",
      "  チャンク 16 を処理中...\n",
      "  チャンク 17 を処理中...\n",
      "  チャンク 18 を処理中...\n",
      "  チャンク 19 を処理中...\n",
      "  チャンク 20 を処理中...\n",
      "  チャンク 21 を処理中...\n",
      "  チャンク 22 を処理中...\n",
      "  チャンク 23 を処理中...\n",
      "  チャンク 24 を処理中...\n",
      "  チャンク 25 を処理中...\n",
      "  チャンク 26 を処理中...\n",
      "  チャンク 27 を処理中...\n",
      "  チャンク 28 を処理中...\n",
      "  チャンク 29 を処理中...\n",
      "  チャンク 30 を処理中...\n",
      "  チャンク 31 を処理中...\n",
      "  チャンク 32 を処理中...\n",
      "  チャンク 33 を処理中...\n",
      "  チャンク 34 を処理中...\n",
      "  チャンク 35 を処理中...\n",
      "  チャンク 36 を処理中...\n",
      "  チャンク 37 を処理中...\n",
      "  チャンク 38 を処理中...\n",
      "  チャンク 39 を処理中...\n",
      "  チャンク 40 を処理中...\n",
      "  チャンク 41 を処理中...\n",
      "  チャンク 42 を処理中...\n",
      "  チャンク 43 を処理中...\n",
      "  チャンク 44 を処理中...\n",
      "  チャンク 45 を処理中...\n",
      "  チャンク 46 を処理中...\n",
      "  チャンク 47 を処理中...\n",
      "  チャンク 48 を処理中...\n",
      "  チャンク 49 を処理中...\n",
      "  チャンク 50 を処理中...\n",
      "処理完了！合計 50 チャンクを処理しました。\n",
      "\n",
      "集計結果（上位5件）:\n",
      "region  channel\n",
      "中部      オンライン      2.483739e+10\n",
      "        パートナー      2.504528e+10\n",
      "        店舗         2.502897e+10\n",
      "        電話         2.506240e+10\n",
      "九州      オンライン      2.491706e+10\n",
      "Name: sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"大規模CSVファイルを少しずつ読み込んで集計する関数\"\"\"\n",
    "def process_large_csv(filename, chunksize=10_000):\n",
    "    \n",
    "    print(f\"ファイル '{filename}' を {chunksize:,}行ずつ処理します...\")\n",
    "    \n",
    "    # 集計結果を保存する変数（最初は空）\n",
    "    aggregated = None\n",
    "    chunk_count = 0\n",
    "    \n",
    "    # ファイルを少しずつ読み込む\n",
    "    for chunk in pd.read_csv(filename, chunksize=chunksize):\n",
    "        chunk_count += 1\n",
    "        print(f\"  チャンク {chunk_count} を処理中...\")\n",
    "        \n",
    "        # 各チャンクでカテゴリ型に変換\n",
    "        chunk[\"region\"] = chunk[\"region\"].astype(\"category\")\n",
    "        chunk[\"channel\"] = chunk[\"channel\"].astype(\"category\")\n",
    "        \n",
    "        # チャンクごとに集計\n",
    "        chunk_result = chunk.groupby(\n",
    "            [\"region\", \"channel\"], \n",
    "            observed=True\n",
    "        )[\"sales\"].sum()\n",
    "        \n",
    "        # 結果を累積していく\n",
    "        if aggregated is None:\n",
    "            # 最初のチャンクの結果をそのまま保存\n",
    "            aggregated = chunk_result\n",
    "        else:\n",
    "            # 2番目以降は既存の結果に加算\n",
    "            # fill_value=0 により、片方にしかないキーも0として扱われる\n",
    "            aggregated = aggregated.add(chunk_result, fill_value=0)\n",
    "    \n",
    "    print(f\"処理完了！合計 {chunk_count} チャンクを処理しました。\")\n",
    "    return aggregated\n",
    "# チャンク処理を実行\n",
    "result = process_large_csv(\"sales_data.csv\", chunksize=20_000)\n",
    "print(\"\\n集計結果（上位5件）:\")\n",
    "print(result.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ベクトル化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ベクトル化しない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apply使用: 0.493秒\n"
     ]
    }
   ],
   "source": [
    "# 売上が1200円を超える割合を地域ごとに計算したい\n",
    "\n",
    "# データの準備\n",
    "N = 10_000_000\n",
    "df_large = pd.DataFrame({\n",
    "    \"region\": np.random.choice(regions, size=N),\n",
    "    \"sales\": np.random.normal(1000, 200, size=N).round(2)\n",
    "})\n",
    "# apply使用\n",
    "def calculate_high_sales_ratio_slow(df):\n",
    "    \"\"\"各地域で売上1200超の割合を計算（遅い方法）\"\"\"\n",
    "    return df.groupby(\"region\")[\"sales\"].apply(\n",
    "        lambda x: (x > 1200).mean()  # 各グループに対してPython関数を実行\n",
    "    )\n",
    "# 速度を表示\n",
    "start = time.perf_counter()\n",
    "result_slow = calculate_high_sales_ratio_slow(df_large)\n",
    "time_slow = time.perf_counter() - start\n",
    "print(f\"apply使用: {time_slow:.3f}秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ベクトル化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ベクトル化: 0.388秒\n",
      "高速化率: 1.3倍\n"
     ]
    }
   ],
   "source": [
    "# ベクトル化\n",
    "def calculate_high_sales_ratio_fast(df):\n",
    "    # まず、売上が1200を超えるかどうかの列を作る\n",
    "    df_with_flag = df.copy()\n",
    "    df_with_flag['is_high_sales'] = df_with_flag[\"sales\"] > 1200\n",
    "    \n",
    "    # True/Falseの平均を取ると、Trueの割合が計算できる\n",
    "    return df_with_flag.groupby(\"region\")[\"is_high_sales\"].mean()\n",
    "# 速度を表示\n",
    "start = time.perf_counter()\n",
    "result_fast = calculate_high_sales_ratio_fast(df_large)\n",
    "time_fast = time.perf_counter() - start\n",
    "print(f\"ベクトル化: {time_fast:.3f}秒\")\n",
    "print(f\"高速化率: {time_slow/time_fast:.1f}倍\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "あまり速くならない？？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "非効率な方法: 5.465秒\n"
     ]
    }
   ],
   "source": [
    "## 悪い例\n",
    "\n",
    "# 準備：数量（qty）列も追加したデータを作成\n",
    "df_multi = pd.DataFrame({\n",
    "    \"region\": np.random.choice(regions, size=N),\n",
    "    \"channel\": np.random.choice(channels, size=N),\n",
    "    \"sales\": np.random.normal(1000, 200, size=N).round(2),\n",
    "    \"qty\": np.random.randint(1, 5, size=N)  # 数量\n",
    "})\n",
    "# 非効率な方法：同じgroupbyを4回も実行\n",
    "start = time.perf_counter()\n",
    "sum_df = df_multi.groupby([\"region\", \"channel\"])['sales'].sum().rename('sales_sum')\n",
    "mean_df = df_multi.groupby([\"region\", \"channel\"])['sales'].mean().rename('sales_mean')\n",
    "qty_df = df_multi.groupby([\"region\", \"channel\"])['qty'].sum().rename('qty_sum')\n",
    "size_df = df_multi.groupby([\"region\", \"channel\"]).size().rename('n')\n",
    "# 結果を結合\n",
    "result_bad = pd.concat([sum_df, mean_df, qty_df, size_df], axis=1).reset_index()\n",
    "# 速度を表示\n",
    "time_bad = time.perf_counter() - start\n",
    "print(f\"非効率な方法: {time_bad:.3f}秒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "効率的な方法: 1.615秒\n",
      "高速化率: 3.4倍\n"
     ]
    }
   ],
   "source": [
    "# 効率的な方法：Named Aggregationで1回のgroupbyで完結\n",
    "start = time.perf_counter()\n",
    "result_good = (\n",
    "    df_multi.groupby([\"region\", \"channel\"], observed=True, sort=False)\n",
    "    .agg(\n",
    "        sales_sum=(\"sales\", \"sum\"),      # 売上の合計を sales_sum という名前で\n",
    "        sales_mean=(\"sales\", \"mean\"),    # 売上の平均を sales_mean という名前で\n",
    "        qty_sum=(\"qty\", \"sum\"),          # 数量の合計を qty_sum という名前で\n",
    "        n=(\"sales\", \"size\"),             # 件数を n という名前で\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "# 速度を表示\n",
    "time_good = time.perf_counter() - start\n",
    "print(f\"効率的な方法: {time_good:.3f}秒\")\n",
    "print(f\"高速化率: {time_bad/time_good:.1f}倍\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.3\n"
     ]
    }
   ],
   "source": [
    "print(pd.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
